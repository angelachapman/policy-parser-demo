{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Any, Tuple\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Shared config and helpers\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Regex for ISO codes - requires specific multi-segment digit patterns\n",
    "ISO_CODE_PATTERN = re.compile(\n",
    "    r\"\\b\"\n",
    "    r\"[A-Z]{2}[\\s\\-]?\"                                             # Two-letter prefix\n",
    "    r\"(?:\"\n",
    "        r\"\\d{2}(?:[\\s\\-]?\\d{2}){1,3}\"                             # Standard: 2-4 segments of 2 digits (CG 00 01 04 13)\n",
    "        r\"|\"\n",
    "        r\"\\d{4}[\\s\\-]?\\d{4}\"                                      # GL format: 2 segments of 4 digits (GL 0169 0001)\n",
    "        r\"|\"\n",
    "        r\"[A-Z]\\s?\\d{3}(?:[\\s\\-]?\\d{2}){2}\"                      # Letter variant: P 023 05 23\n",
    "        r\"|\"\n",
    "        r\"\\d{2}[\\s\\-]?\\d{2}[\\s\\-]?\\([Ee]d\\.?[\\s\\-]?\\d{2}[/\\-]\\d{2}\\)\"  # Edition: 21 70 (Ed. 01/15)\n",
    "    r\")\"\n",
    "    r\"\\b\"\n",
    ")\n",
    "\n",
    "def get_header_footer_spans(\n",
    "    page: fitz.Page,\n",
    "    header_fraction: float,\n",
    "    footer_fraction: float,\n",
    ") -> List[Tuple[str, Tuple[float, float, float, float]]]:\n",
    "    rect = page.rect\n",
    "    height = rect.height\n",
    "\n",
    "    header_cutoff = rect.y0 + header_fraction * height\n",
    "    footer_cutoff = rect.y1 - footer_fraction * height\n",
    "\n",
    "    spans = []\n",
    "    text_dict = page.get_text(\"dict\")\n",
    "\n",
    "    for block in text_dict.get(\"blocks\", []):\n",
    "        for line in block.get(\"lines\", []):\n",
    "            for span in line.get(\"spans\", []):\n",
    "                text = span.get(\"text\", \"\").strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                x0, y0, x1, y1 = span[\"bbox\"]\n",
    "                in_header = y0 <= header_cutoff\n",
    "                in_footer = y1 >= footer_cutoff\n",
    "                if in_header or in_footer:\n",
    "                    spans.append((text, (x0, y0, x1, y1)))\n",
    "\n",
    "    return spans\n",
    "\n",
    "\n",
    "def build_page_to_codes_map(\n",
    "    codes_dict: Dict[str, List[Dict[str, Any]]]\n",
    ") -> Dict[int, List[str]]:\n",
    "    page_to_codes: Dict[int, List[str]] = defaultdict(list)\n",
    "    for code, occurrences in codes_dict.items():\n",
    "        for occ in occurrences:\n",
    "            page = occ[\"page\"]\n",
    "            page_to_codes[page].append(code)\n",
    "    return page_to_codes\n",
    "\n",
    "def pages_to_fix_from_initial_output(pdf_path: str, initial_codes: dict) -> list[int]:\n",
    "    # page -> set(unique codes)\n",
    "    page_to_codes = defaultdict(set)\n",
    "    for code, occs in initial_codes.items():\n",
    "        for occ in occs:\n",
    "            page_to_codes[int(occ[\"page\"])].add(code)\n",
    "\n",
    "    # total pages\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        all_pages = set(range(1, len(doc) + 1))\n",
    "\n",
    "    missing_pages = sorted([p for p in all_pages if p not in page_to_codes])\n",
    "    ambiguous_pages = sorted([p for p, codeset in page_to_codes.items() if len(codeset) >= 2])\n",
    "\n",
    "    return sorted(set(missing_pages) | set(ambiguous_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Stage 1: regex-only extraction\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def extract_iso_codes_from_headers_footers(\n",
    "    pdf_path: str,\n",
    "    header_fraction: float = 0.12,\n",
    "    footer_fraction: float = 0.12,\n",
    ") -> Dict[str, List[Dict[str, Any]]]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    codes = defaultdict(list)\n",
    "\n",
    "    try:\n",
    "        for page_index, page in enumerate(doc):\n",
    "            page_num = page_index + 1\n",
    "            spans = get_header_footer_spans(\n",
    "                page,\n",
    "                header_fraction=header_fraction,\n",
    "                footer_fraction=footer_fraction,\n",
    "            )\n",
    "\n",
    "            for text, _bbox in spans:\n",
    "                for match in ISO_CODE_PATTERN.finditer(text):\n",
    "                    code = \" \".join(match.group(0).split())\n",
    "                    codes[code].append(\n",
    "                        {\n",
    "                            \"page\": page_num,\n",
    "                            \"snippet\": text,\n",
    "                        }\n",
    "                    )\n",
    "    finally:\n",
    "        doc.close()\n",
    "\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a713dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Stage 2: LLM cleanup for missing or ambiguous pages only\n",
    "# This makes the assumption that each page corresponds to at most one policy/endorsement/exclusion\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "base_prompt = (\n",
    "            \"You are given the text of a single page from a commercial insurance policy.\\n\"\n",
    "            \"Find one ISO (Insurance Services Office) form code if present. A valid code looks like: CG 20 37 12 19. Sometimes,\"\n",
    "            \"there are variants on this pattern (extra letters, different date formats, etc)\\n\"\n",
    "            \"Return exactly one code or the string NONE.\\n\" \\\n",
    "            \"If there are multiple codes mentioned, use page context to determine the correct one. \" \\\n",
    "            \"The correct code is often near the top or bottom of the page.\"\n",
    "        )\n",
    "\n",
    "async def refine_iso_codes_with_llm(\n",
    "    pdf_path: str,\n",
    "    initial_codes: Dict[str, List[Dict[str, Any]]],\n",
    "    model_name: str = \"gpt-5-mini\",\n",
    ") -> Dict[str, List[Dict[str, Any]]]:\n",
    "    page_to_codes = build_page_to_codes_map(initial_codes)\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    num_pages = len(doc)\n",
    "\n",
    "    try:\n",
    "        all_pages = set(range(1, num_pages + 1))\n",
    "\n",
    "        pages_to_fix = pages_to_fix_from_initial_output(pdf_path, initial_codes)\n",
    "\n",
    "        print(f\"Using LLM to check pages: {pages_to_fix}\")\n",
    "\n",
    "        llm = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            temperature=0.0,  # deterministic\n",
    "        )\n",
    "\n",
    "        final_page_codes = {}\n",
    "\n",
    "        # Pages already clean\n",
    "        for page in sorted(all_pages - set(pages_to_fix)):\n",
    "            final_page_codes[page] = page_to_codes[page][0]\n",
    "\n",
    "        for page_num in pages_to_fix:\n",
    "            page = doc[page_num - 1]\n",
    "            page_text = page.get_text(\"text\") or \"\"\n",
    "\n",
    "            prompt = base_prompt + \"\\nPage text:\\n\" + page_text\n",
    "\n",
    "            response = await llm.ainvoke(prompt)\n",
    "            raw = getattr(response, \"content\", str(response))\n",
    "            print(f\"Page num: {page_num}, LLM raw output: {raw}\")\n",
    "            code = raw.strip()\n",
    "\n",
    "            if code.upper() == \"NONE\":\n",
    "                final_page_codes[page_num] = \"NONE\"\n",
    "            else:\n",
    "                final_page_codes[page_num] = \" \".join(code.split())\n",
    "\n",
    "    finally:\n",
    "        doc.close()\n",
    "\n",
    "    # Convert from page->code format to code->pages format (same as initial_codes)\n",
    "    result = defaultdict(list)\n",
    "    \n",
    "    for page_num, code in sorted(final_page_codes.items()):\n",
    "        if code != \"NONE\":\n",
    "            snippet = \"\"\n",
    "            \n",
    "            # If this page wasn't processed by LLM, preserve original snippet\n",
    "            if page_num not in pages_to_fix:\n",
    "                for orig_code, occurrences in initial_codes.items():\n",
    "                    for occ in occurrences:\n",
    "                        if occ[\"page\"] == page_num and orig_code == code:\n",
    "                            snippet = occ[\"snippet\"]\n",
    "                            break\n",
    "            \n",
    "            result[code].append({\n",
    "                \"page\": page_num,\n",
    "                \"snippet\": snippet\n",
    "            })\n",
    "    \n",
    "    return dict(result)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Example usage\n",
    "# -------------------------------------------------------------------\n",
    "# pdf_path = \"your_policy.pdf\"\n",
    "# initial = extract_iso_codes_from_headers_footers(pdf_path)\n",
    "# refined = refine_iso_codes_with_llm(pdf_path, initial)\n",
    "# refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"examples/general-liability-forms.pdf\"\n",
    "\n",
    "start_time = time.time()\n",
    "initial = extract_iso_codes_from_headers_footers(pdf_path)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Regex extraction took {elapsed_time:.2f} seconds, gave {len(initial)} codes\")\n",
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "result = await refine_iso_codes_with_llm(pdf_path, initial) \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"LLM refinement took {elapsed_time:.2f} seconds, gave {len(result)} codes\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if results look good and have all the correct codes, we can store them as ground truth\n",
    "# leave it commented out so that we don't accidentally store results without checking them first\n",
    "\n",
    "#import json\n",
    "#with open(\"examples/Michigan-Hospitality-Liability-Forms-gt.json\", \"w\") as f:\n",
    "#    json.dump(result, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da343f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code allows you to read in the json ground truth in case you want to inspect it or compare\n",
    "import json\n",
    "with open(\"examples/general-liability-forms-gt.json\", \"r\") as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "len(ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
